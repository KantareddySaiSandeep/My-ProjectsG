{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import Dropout\n",
    "from keras import applications\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, merge, Input\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "import glob\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import imageio as im\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications import vgg16\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer, Activation,GlobalAveragePooling2D,concatenate\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from bs4 import BeautifulSoup\n",
    "from os.path import abspath\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import shutil\n",
    "import cv2\n",
    "image_size=128\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, Conv2D, Dropout, Flatten, MaxPooling2D,Embedding,LSTM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10k_tested.xlsx',\n",
       " 'Training_Data',\n",
       " 'LSTM_text.h5',\n",
       " 'Human_Organisation_Bios.xlsx',\n",
       " 'shapes_cnn_mobile.h5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('/kaggle/input/text-image/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=r'/kaggle/input/text-image/Training_Data/Training_Data/'\n",
    "image_size=128\n",
    "classes=os.listdir(train_path)\n",
    "def load_train(train_path, image_size, classes):\n",
    "    images = []\n",
    "    labels = []\n",
    "    img_names = []\n",
    "\n",
    "    print('Going to read training images')\n",
    "    for fields in classes:   \n",
    "        index = classes.index(fields)\n",
    "        print('Now going to read {} files (Index: {})'.format(fields, index))\n",
    "        path = os.path.join(train_path, fields, '*g')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files:\n",
    "            image = cv2.imread(fl)\n",
    "            image = cv2.resize(image, (image_size, image_size),0,0, cv2.INTER_LINEAR)\n",
    "            image = image.astype(np.float32)\n",
    "            #image = np.multiply(image, 1.0 / 255.0)\n",
    "            images.append(image)\n",
    "            label = np.zeros(len(classes))\n",
    "            label[index] = 1.0\n",
    "            labels.append(label)\n",
    "            #labels.append(fields)#for regression\n",
    "            flbase = os.path.basename(fl)\n",
    "            img_names.append(flbase)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "# =============================================================================\n",
    "#     labels=np.reshape(labels,(-1,1))\n",
    "# =============================================================================\n",
    "    img_names = np.array(img_names)\n",
    "\n",
    "    return images, labels, img_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to read training images\n",
      "Now going to read Humans files (Index: 0)\n",
      "Now going to read Organisations files (Index: 1)\n"
     ]
    }
   ],
   "source": [
    "images, labels, img_names = load_train(train_path, image_size, classes)\n",
    "images, labels, img_names = shuffle(images, labels, img_names) \n",
    "x_train,x_test,y_train,y_test=train_test_split(images,labels, test_size=0.33)\n",
    "x_train = x_train.reshape(x_train.shape[0], 128, 128, 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], 128, 128, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_excel(r'/kaggle/input/text-image/Human_Organisation_Bios.xlsx')\n",
    "train=train.replace('Human','Humans')\n",
    "train=train.replace('Organisation','Organisations')\n",
    "enc = LabelEncoder().fit(train['Classification'])\n",
    "encoded = enc.transform(train['Classification'])\n",
    "encoded = keras.utils.to_categorical(encoded)\n",
    "test1=encoded\n",
    "train=train.drop(['Classification'],axis=1)\n",
    "for i in train:\n",
    "    train[i]=train[i].astype(str)\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train['Bios'])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train['Bios'])\n",
    "# X_test = tokenizer.texts_to_sequences(sentences_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "maxlen = 1024\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "# X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_model=load_model('/kaggle/input/text-image/shapes_cnn_mobile.h5')\n",
    "intermediate_layer_model = Model(inputs=e_model.input,outputs=e_model.get_layer('dense_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_model2=load_model('/kaggle/input/text-image/LSTM_text.h5')\n",
    "intermediate_layer_model2 = Model(inputs=e_model2.input,outputs=e_model2.get_layer('FC1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The name \"dense_1\" is used 2 times in the model. All layer names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e0552758cd07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mfull_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintermediate_layer_model2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mintermediate_layer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.000001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 241\u001b[0;31m             self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1521\u001b[0m             raise ValueError('The name \"' + name + '\" is used ' +\n\u001b[1;32m   1522\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1523\u001b[0;31m                              \u001b[0;34m' times in the model. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1524\u001b[0m                              'All layer names should be unique.')\n\u001b[1;32m   1525\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnetwork_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"dense_1\" is used 2 times in the model. All layer names should be unique."
     ]
    }
   ],
   "source": [
    "max_words = 1024\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "X_train_image = images\n",
    "X_train_text = X_train\n",
    "y_train = test1\n",
    "\n",
    "#num_classes = np.max(y_train) + 1\n",
    "#print(num_classes)\n",
    "# Text input branch - just a simple MLP\n",
    "text_inputs = Input(shape=(max_words,))\n",
    "# # branch_1 = Dense(1024, activation='relu',kernel_regularizer=regularizers.l2(0.01))(text_inputs)\n",
    "# # branch_1=BatchNormalization()(branch_1)\n",
    "# branch_1 = Embedding(max_words,50,input_length=maxlen)(text_inputs)\n",
    "# branch_1 = LSTM(64)(branch_1)\n",
    "# branch_1 = Dense(256,name='FC1')(branch_1)\n",
    "\n",
    "# # Image input branch - a pre-trained Inception module followed by an added fully connected layer\n",
    "# #base_model = applications.InceptionV3(weights='imagenet', include_top=False)\n",
    "# base_model=applications.MobileNet(weights='imagenet',include_top=False)\n",
    "# # Freeze Inception's weights - we don't want to train these\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "\n",
    "# # add a fully connected layer after Inception - we do want to train these\n",
    "# branch_2 = base_model.output\n",
    "# branch_2 = GlobalAveragePooling2D()(branch_2)\n",
    "# branch_2 = Dense(1024, activation='relu')(branch_2)\n",
    "# branch_2 = BatchNormalization()(branch_2)\n",
    "# merge the text input branch and the image input branch and add another fully connected layer\n",
    "joint = concatenate([intermediate_layer_model2.output, intermediate_layer_model.output])\n",
    "joint = Dense(512, activation='relu')(joint)\n",
    "joint=BatchNormalization()(joint)\n",
    "joint = Dropout(0.7)(joint)\n",
    "predictions = Dense(2, activation='softmax')(joint)\n",
    "\n",
    "full_model = Model(inputs=[intermediate_layer_model2.input,intermediate_layer_model.input], outputs=[predictions])\n",
    "\n",
    "opt=Adam(learning_rate=0.000001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "\n",
    "full_model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=opt,\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "history = full_model.fit([X_train_text, X_train_image], y_train,\n",
    "                         epochs=epochs, batch_size=batch_size,\n",
    "                         verbose=1, validation_split=0.3, shuffle=True)\n",
    "full_model.save('text_image2_lr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5908 samples, validate on 2532 samples\n",
      "Epoch 1/100\n",
      "5908/5908 [==============================] - 232s 39ms/step - loss: 1.4486 - accuracy: 0.5184 - val_loss: 0.8802 - val_accuracy: 0.2085\n",
      "Epoch 2/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.4162 - accuracy: 0.5103 - val_loss: 0.8612 - val_accuracy: 0.2859\n",
      "Epoch 3/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.3486 - accuracy: 0.5171 - val_loss: 0.8246 - val_accuracy: 0.3187\n",
      "Epoch 4/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.3094 - accuracy: 0.5245 - val_loss: 0.8023 - val_accuracy: 0.3479\n",
      "Epoch 5/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.2894 - accuracy: 0.5044 - val_loss: 0.7864 - val_accuracy: 0.3543\n",
      "Epoch 6/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.2796 - accuracy: 0.5081 - val_loss: 0.7761 - val_accuracy: 0.3645\n",
      "Epoch 7/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.2824 - accuracy: 0.5218 - val_loss: 0.7702 - val_accuracy: 0.3788\n",
      "Epoch 8/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.3007 - accuracy: 0.5080 - val_loss: 0.7631 - val_accuracy: 0.3989\n",
      "Epoch 9/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.3050 - accuracy: 0.4990 - val_loss: 0.7626 - val_accuracy: 0.4068\n",
      "Epoch 10/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.2632 - accuracy: 0.5073 - val_loss: 0.7599 - val_accuracy: 0.4198\n",
      "Epoch 11/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.2424 - accuracy: 0.5069 - val_loss: 0.7660 - val_accuracy: 0.4056\n",
      "Epoch 12/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.2873 - accuracy: 0.5134 - val_loss: 0.7642 - val_accuracy: 0.4167\n",
      "Epoch 13/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.2719 - accuracy: 0.5169 - val_loss: 0.7589 - val_accuracy: 0.4344\n",
      "Epoch 14/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.2430 - accuracy: 0.5024 - val_loss: 0.7613 - val_accuracy: 0.4246\n",
      "Epoch 15/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.2691 - accuracy: 0.5149 - val_loss: 0.7638 - val_accuracy: 0.4182\n",
      "Epoch 16/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.2697 - accuracy: 0.5125 - val_loss: 0.7689 - val_accuracy: 0.4100\n",
      "Epoch 17/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.2059 - accuracy: 0.5264 - val_loss: 0.7697 - val_accuracy: 0.4088\n",
      "Epoch 18/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.2653 - accuracy: 0.5088 - val_loss: 0.7678 - val_accuracy: 0.4147\n",
      "Epoch 19/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.2206 - accuracy: 0.5198 - val_loss: 0.7770 - val_accuracy: 0.3949\n",
      "Epoch 20/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.2436 - accuracy: 0.5118 - val_loss: 0.7794 - val_accuracy: 0.3855\n",
      "Epoch 21/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.2003 - accuracy: 0.5178 - val_loss: 0.7811 - val_accuracy: 0.3772\n",
      "Epoch 22/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.2376 - accuracy: 0.5140 - val_loss: 0.7842 - val_accuracy: 0.3697\n",
      "Epoch 23/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.2024 - accuracy: 0.5274 - val_loss: 0.7814 - val_accuracy: 0.3709\n",
      "Epoch 24/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.2586 - accuracy: 0.5078 - val_loss: 0.7913 - val_accuracy: 0.3527\n",
      "Epoch 25/100\n",
      "5908/5908 [==============================] - 230s 39ms/step - loss: 1.2593 - accuracy: 0.5064 - val_loss: 0.7979 - val_accuracy: 0.3369\n",
      "Epoch 26/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.2516 - accuracy: 0.5073 - val_loss: 0.7936 - val_accuracy: 0.3373\n",
      "Epoch 27/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.2032 - accuracy: 0.5247 - val_loss: 0.7973 - val_accuracy: 0.3302\n",
      "Epoch 28/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.1941 - accuracy: 0.5237 - val_loss: 0.8014 - val_accuracy: 0.2978\n",
      "Epoch 29/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.2185 - accuracy: 0.5107 - val_loss: 0.7973 - val_accuracy: 0.3049\n",
      "Epoch 30/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.2111 - accuracy: 0.5256 - val_loss: 0.8029 - val_accuracy: 0.2934\n",
      "Epoch 31/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.2078 - accuracy: 0.5218 - val_loss: 0.8033 - val_accuracy: 0.2895\n",
      "Epoch 32/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.2020 - accuracy: 0.5195 - val_loss: 0.8134 - val_accuracy: 0.2701\n",
      "Epoch 33/100\n",
      "5908/5908 [==============================] - 230s 39ms/step - loss: 1.2592 - accuracy: 0.5095 - val_loss: 0.8083 - val_accuracy: 0.2749\n",
      "Epoch 34/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.1696 - accuracy: 0.5278 - val_loss: 0.8072 - val_accuracy: 0.2729\n",
      "Epoch 35/100\n",
      "5908/5908 [==============================] - 234s 40ms/step - loss: 1.1948 - accuracy: 0.5176 - val_loss: 0.8109 - val_accuracy: 0.2658\n",
      "Epoch 36/100\n",
      "5908/5908 [==============================] - 236s 40ms/step - loss: 1.2093 - accuracy: 0.5188 - val_loss: 0.8191 - val_accuracy: 0.2492\n",
      "Epoch 37/100\n",
      "5908/5908 [==============================] - 231s 39ms/step - loss: 1.1541 - accuracy: 0.5332 - val_loss: 0.8173 - val_accuracy: 0.2425\n",
      "Epoch 38/100\n",
      "5908/5908 [==============================] - 232s 39ms/step - loss: 1.1913 - accuracy: 0.5200 - val_loss: 0.8246 - val_accuracy: 0.2247\n",
      "Epoch 39/100\n",
      "5908/5908 [==============================] - 233s 39ms/step - loss: 1.1714 - accuracy: 0.5257 - val_loss: 0.8219 - val_accuracy: 0.2259\n",
      "Epoch 40/100\n",
      "5908/5908 [==============================] - 230s 39ms/step - loss: 1.2130 - accuracy: 0.5120 - val_loss: 0.8259 - val_accuracy: 0.2156\n",
      "Epoch 41/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.1991 - accuracy: 0.5256 - val_loss: 0.8361 - val_accuracy: 0.2038\n",
      "Epoch 42/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.1931 - accuracy: 0.5135 - val_loss: 0.8363 - val_accuracy: 0.1971\n",
      "Epoch 43/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.1719 - accuracy: 0.5273 - val_loss: 0.8385 - val_accuracy: 0.1951\n",
      "Epoch 44/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1723 - accuracy: 0.5306 - val_loss: 0.8355 - val_accuracy: 0.2002\n",
      "Epoch 45/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.1744 - accuracy: 0.5256 - val_loss: 0.8476 - val_accuracy: 0.1809\n",
      "Epoch 46/100\n",
      "5908/5908 [==============================] - 224s 38ms/step - loss: 1.1729 - accuracy: 0.5308 - val_loss: 0.8512 - val_accuracy: 0.1734\n",
      "Epoch 47/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.2073 - accuracy: 0.5245 - val_loss: 0.8529 - val_accuracy: 0.1706\n",
      "Epoch 48/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1961 - accuracy: 0.5244 - val_loss: 0.8517 - val_accuracy: 0.1754\n",
      "Epoch 49/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.1916 - accuracy: 0.5283 - val_loss: 0.8556 - val_accuracy: 0.1702\n",
      "Epoch 50/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.1615 - accuracy: 0.5281 - val_loss: 0.8530 - val_accuracy: 0.1718\n",
      "Epoch 51/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.1737 - accuracy: 0.5229 - val_loss: 0.8583 - val_accuracy: 0.1659\n",
      "Epoch 52/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.1665 - accuracy: 0.5262 - val_loss: 0.8594 - val_accuracy: 0.1572\n",
      "Epoch 53/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.1964 - accuracy: 0.5212 - val_loss: 0.8632 - val_accuracy: 0.1442\n",
      "Epoch 54/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1676 - accuracy: 0.5242 - val_loss: 0.8748 - val_accuracy: 0.1311\n",
      "Epoch 55/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.2094 - accuracy: 0.5217 - val_loss: 0.8672 - val_accuracy: 0.1363\n",
      "Epoch 56/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.1380 - accuracy: 0.5305 - val_loss: 0.8792 - val_accuracy: 0.1327\n",
      "Epoch 57/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1745 - accuracy: 0.5210 - val_loss: 0.8780 - val_accuracy: 0.1280\n",
      "Epoch 58/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1562 - accuracy: 0.5355 - val_loss: 0.8805 - val_accuracy: 0.1181\n",
      "Epoch 59/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1426 - accuracy: 0.5298 - val_loss: 0.8837 - val_accuracy: 0.1122\n",
      "Epoch 60/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1541 - accuracy: 0.5374 - val_loss: 0.8855 - val_accuracy: 0.1098\n",
      "Epoch 61/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.1647 - accuracy: 0.5357 - val_loss: 0.8894 - val_accuracy: 0.1110\n",
      "Epoch 62/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1664 - accuracy: 0.5359 - val_loss: 0.8894 - val_accuracy: 0.1094\n",
      "Epoch 63/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.1667 - accuracy: 0.5240 - val_loss: 0.8964 - val_accuracy: 0.1003\n",
      "Epoch 64/100\n",
      "5908/5908 [==============================] - 229s 39ms/step - loss: 1.1382 - accuracy: 0.5327 - val_loss: 0.9006 - val_accuracy: 0.1062\n",
      "Epoch 65/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1391 - accuracy: 0.5421 - val_loss: 0.9031 - val_accuracy: 0.1106\n",
      "Epoch 66/100\n",
      "5908/5908 [==============================] - 224s 38ms/step - loss: 1.1554 - accuracy: 0.5357 - val_loss: 0.8991 - val_accuracy: 0.1110\n",
      "Epoch 67/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1410 - accuracy: 0.5361 - val_loss: 0.9047 - val_accuracy: 0.1090\n",
      "Epoch 68/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1377 - accuracy: 0.5256 - val_loss: 0.9062 - val_accuracy: 0.1102\n",
      "Epoch 69/100\n",
      "5908/5908 [==============================] - 232s 39ms/step - loss: 1.1564 - accuracy: 0.5330 - val_loss: 0.9066 - val_accuracy: 0.1130\n",
      "Epoch 70/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.1039 - accuracy: 0.5340 - val_loss: 0.9133 - val_accuracy: 0.1122\n",
      "Epoch 71/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1152 - accuracy: 0.5325 - val_loss: 0.9162 - val_accuracy: 0.1090\n",
      "Epoch 72/100\n",
      "5908/5908 [==============================] - 224s 38ms/step - loss: 1.1432 - accuracy: 0.5347 - val_loss: 0.9222 - val_accuracy: 0.0976\n",
      "Epoch 73/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.1391 - accuracy: 0.5374 - val_loss: 0.9238 - val_accuracy: 0.1011\n",
      "Epoch 74/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.1242 - accuracy: 0.5465 - val_loss: 0.9212 - val_accuracy: 0.0983\n",
      "Epoch 75/100\n",
      "5908/5908 [==============================] - 231s 39ms/step - loss: 1.1079 - accuracy: 0.5386 - val_loss: 0.9288 - val_accuracy: 0.0948\n",
      "Epoch 76/100\n",
      "5908/5908 [==============================] - 231s 39ms/step - loss: 1.1109 - accuracy: 0.5406 - val_loss: 0.9328 - val_accuracy: 0.0829\n",
      "Epoch 77/100\n",
      "5908/5908 [==============================] - 233s 39ms/step - loss: 1.1685 - accuracy: 0.5333 - val_loss: 0.9363 - val_accuracy: 0.0845\n",
      "Epoch 78/100\n",
      "5908/5908 [==============================] - 238s 40ms/step - loss: 1.1128 - accuracy: 0.5445 - val_loss: 0.9363 - val_accuracy: 0.0841\n",
      "Epoch 79/100\n",
      "5908/5908 [==============================] - 232s 39ms/step - loss: 1.0986 - accuracy: 0.5471 - val_loss: 0.9375 - val_accuracy: 0.0806\n",
      "Epoch 80/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.0964 - accuracy: 0.5513 - val_loss: 0.9404 - val_accuracy: 0.0786\n",
      "Epoch 81/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.1387 - accuracy: 0.5384 - val_loss: 0.9440 - val_accuracy: 0.0814\n",
      "Epoch 82/100\n",
      "5908/5908 [==============================] - 229s 39ms/step - loss: 1.1503 - accuracy: 0.5405 - val_loss: 0.9485 - val_accuracy: 0.0707\n",
      "Epoch 83/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.1230 - accuracy: 0.5427 - val_loss: 0.9465 - val_accuracy: 0.0707\n",
      "Epoch 84/100\n",
      "5908/5908 [==============================] - 229s 39ms/step - loss: 1.1427 - accuracy: 0.5379 - val_loss: 0.9543 - val_accuracy: 0.0648\n",
      "Epoch 85/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1229 - accuracy: 0.5366 - val_loss: 0.9558 - val_accuracy: 0.0608\n",
      "Epoch 86/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1064 - accuracy: 0.5354 - val_loss: 0.9608 - val_accuracy: 0.0585\n",
      "Epoch 87/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.1336 - accuracy: 0.5428 - val_loss: 0.9631 - val_accuracy: 0.0616\n",
      "Epoch 88/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1134 - accuracy: 0.5393 - val_loss: 0.9635 - val_accuracy: 0.0588\n",
      "Epoch 89/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.0890 - accuracy: 0.5518 - val_loss: 0.9679 - val_accuracy: 0.0557\n",
      "Epoch 90/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1389 - accuracy: 0.5340 - val_loss: 0.9699 - val_accuracy: 0.0525\n",
      "Epoch 91/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.1008 - accuracy: 0.5437 - val_loss: 0.9725 - val_accuracy: 0.0486\n",
      "Epoch 92/100\n",
      "5908/5908 [==============================] - 226s 38ms/step - loss: 1.1191 - accuracy: 0.5459 - val_loss: 0.9753 - val_accuracy: 0.0498\n",
      "Epoch 93/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.1566 - accuracy: 0.5381 - val_loss: 0.9798 - val_accuracy: 0.0423\n",
      "Epoch 94/100\n",
      "5908/5908 [==============================] - 230s 39ms/step - loss: 1.1235 - accuracy: 0.5391 - val_loss: 0.9788 - val_accuracy: 0.0494\n",
      "Epoch 95/100\n",
      "5908/5908 [==============================] - 228s 39ms/step - loss: 1.1314 - accuracy: 0.5443 - val_loss: 0.9862 - val_accuracy: 0.0419\n",
      "Epoch 96/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.0761 - accuracy: 0.5587 - val_loss: 0.9869 - val_accuracy: 0.0399\n",
      "Epoch 97/100\n",
      "5908/5908 [==============================] - 227s 38ms/step - loss: 1.0778 - accuracy: 0.5428 - val_loss: 0.9879 - val_accuracy: 0.0399\n",
      "Epoch 98/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.0872 - accuracy: 0.5491 - val_loss: 0.9918 - val_accuracy: 0.0367\n",
      "Epoch 99/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.0945 - accuracy: 0.5482 - val_loss: 0.9917 - val_accuracy: 0.0407\n",
      "Epoch 100/100\n",
      "5908/5908 [==============================] - 225s 38ms/step - loss: 1.0868 - accuracy: 0.5486 - val_loss: 0.9992 - val_accuracy: 0.0403\n"
     ]
    }
   ],
   "source": [
    "max_words = 1024\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "X_train_image = images\n",
    "X_train_text = X_train\n",
    "y_train = test1\n",
    "\n",
    "#num_classes = np.max(y_train) + 1\n",
    "#print(num_classes)\n",
    "# Text input branch - just a simple MLP\n",
    "text_inputs = Input(shape=(max_words,))\n",
    "# # branch_1 = Dense(1024, activation='relu',kernel_regularizer=regularizers.l2(0.01))(text_inputs)\n",
    "# # branch_1=BatchNormalization()(branch_1)\n",
    "# branch_1 = Embedding(max_words,50,input_length=maxlen)(text_inputs)\n",
    "# branch_1 = LSTM(64)(branch_1)\n",
    "# branch_1 = Dense(256,name='FC1')(branch_1)\n",
    "\n",
    "# # Image input branch - a pre-trained Inception module followed by an added fully connected layer\n",
    "# #base_model = applications.InceptionV3(weights='imagenet', include_top=False)\n",
    "# base_model=applications.MobileNet(weights='imagenet',include_top=False)\n",
    "# # Freeze Inception's weights - we don't want to train these\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "\n",
    "# # add a fully connected layer after Inception - we do want to train these\n",
    "# branch_2 = base_model.output\n",
    "# branch_2 = GlobalAveragePooling2D()(branch_2)\n",
    "# branch_2 = Dense(1024, activation='relu')(branch_2)\n",
    "# branch_2 = BatchNormalization()(branch_2)\n",
    "# merge the text input branch and the image input branch and add another fully connected layer\n",
    "joint = concatenate([intermediate_layer_model2.output, intermediate_layer_model.output])\n",
    "joint = Dense(512, activation='relu')(joint)\n",
    "joint=BatchNormalization()(joint)\n",
    "joint = Dropout(0.7)(joint)\n",
    "predictions = Dense(2, activation='softmax')(joint)\n",
    "\n",
    "full_model = Model(inputs=[intermediate_layer_model2.input,intermediate_layer_model.input], outputs=[predictions])\n",
    "\n",
    "opt=Adam(learning_rate=0.000001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "\n",
    "full_model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=opt,\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "history = full_model.fit([X_train_text, X_train_image], y_train,\n",
    "                         epochs=epochs, batch_size=batch_size,\n",
    "                         verbose=1, validation_split=0.3, shuffle=True)\n",
    "full_model.save('text_image2_lr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=pd.DataFrame(columns=['Bios'])\n",
    "# x['Bios']=['Creative available for commission work. Specializing in concept development, illustration, murals, graphics and 3-D set design & construction.']\n",
    "# max_len = 100\n",
    "# cnn_texts_seq = tokenizer.texts_to_sequences(x['Bios'])\n",
    "# print(cnn_texts_seq[0])\n",
    "# cnn_texts_mat = pad_sequences(cnn_texts_seq,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y=[]\n",
    "# for i in df['ScreenName']:\n",
    "#     link='https://twitter.com/'+i\n",
    "#     try:\n",
    "#         html_page = urllib.request.urlopen(link,timeout=10)\n",
    "#     except (urllib.error.HTTPError,urllib.error.URLError):\n",
    "#         print('I cannot handle this situation!')\n",
    "#     soup = BeautifulSoup(html_page)\n",
    "#     if os.path.exists('twitter'):\n",
    "#         pass\n",
    "#     else:\n",
    "#         os.mkdir('twitter')\n",
    "#     urllib.request.urlretrieve(soup.find(class_=\"ProfileAvatar-image\").get('src'),  r'/kaggle/input/twitter'+\"//\"+link.split('/')[3]+'.jpg')\n",
    "#     text=soup.find(class_=\"ProfileHeaderCard-bio u-dir\").get_text()\n",
    "#     x=pd.DataFrame(columns=['Bios'])\n",
    "#     x['Bios']=[\"'\"+text+\"'\"]\n",
    "#     max_len = 100\n",
    "#     cnn_texts_seq = tokenizer.texts_to_sequences(x['Bios'])\n",
    "#     cnn_texts_mat = pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "#     images=[]\n",
    "#     image = cv2.imread(r'/kaggle/input/twitter'+\"//\"+link.split('/')[3]+'.jpg')\n",
    "#     image1 = cv2.resize(image, (image_size, image_size),0,0, cv2.INTER_LINEAR)\n",
    "#     images.append(image1)\n",
    "#     images = np.array(images, dtype=np.uint8)\n",
    "#     images = images.astype('float32')\n",
    "#     #images = np.multiply(images, 1.0/255.0)\n",
    "#     print(model.predict([cnn_texts_mat,images]))\n",
    "# #     for i in model.predict([cnn_texts_mat,images]):\n",
    "# #             if i<0.5:\n",
    "# #                 print('It is a human profile')\n",
    "# #                 y.append('Human')\n",
    "# #             else:\n",
    "# #                 print('It is an organisation profile')\n",
    "# #                 y.append('Organisation')\n",
    "#     shutil.rmtree('twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link=input('')\n",
    "# try:\n",
    "#     html_page = urllib.request.urlopen(link,timeout=10)\n",
    "# except (urllib.error.HTTPError,urllib.error.URLError):\n",
    "#     print('I cannot handle this situation!')\n",
    "# soup = BeautifulSoup(html_page)\n",
    "# if os.path.exists('twitter'):\n",
    "#     pass\n",
    "# else:\n",
    "#     os.mkdir('twitter')\n",
    "# urllib.request.urlretrieve(soup.find(class_=\"ProfileAvatar-image\").get('src'),  r'/kaggle/working/twitter'+\"/\"+link.split('/')[3]+'.jpg')\n",
    "# text=soup.find(class_=\"ProfileHeaderCard-bio u-dir\").get_text()\n",
    "# x=pd.DataFrame(columns=['Bios'])\n",
    "# x['Bios']=[\"'\"+text+\"'\"]\n",
    "# max_len = 1024\n",
    "# cnn_texts_seq = tokenizer.texts_to_sequences(x['Bios'])\n",
    "# cnn_texts_mat = pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "# image2=[]\n",
    "# image = cv2.imread(r'/kaggle/working/twitter'+\"/\"+link.split('/')[3]+'.jpg')\n",
    "# image1 = cv2.resize(image, (image_size, image_size),0,0, cv2.INTER_LINEAR)\n",
    "# image2.append(image1)\n",
    "# image2 = np.array(image2, dtype=np.uint8)\n",
    "# image2 = image2.astype('float32')\n",
    "# #images = np.multiply(images, 1.0/255.0)\n",
    "# print(np.argmax(full_model.predict([cnn_texts_mat,image2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
